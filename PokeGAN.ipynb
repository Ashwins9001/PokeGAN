{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0503d21",
   "metadata": {},
   "source": [
    "## Prepare images for training\n",
    "\n",
    "Resize images to 64 x 64 x 1. For simplicity's sake, only use single channel from RGB images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f541eea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import image\n",
    "from os import listdir\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from numpy import expand_dims\n",
    "\n",
    "\n",
    "def load_samples():\n",
    "    loaded_img = []\n",
    "\n",
    "    for file in listdir('C:/Users/Nitro/Documents/pokegan/pokemon_jpg/pokemon_jpg'):\n",
    "        img = Image.open('C:/Users/Nitro/Documents/pokegan/pokemon_jpg/pokemon_jpg/' + file)\n",
    "        red, green, blue = img.split()\n",
    "        img_resized = red.resize((64, 64))\n",
    "        im2arr = np.array(img_resized)\n",
    "        loaded_img.append(im2arr)\n",
    "\n",
    "    X = np.asarray(loaded_img)\n",
    "    X = expand_dims(X, axis=-1)\n",
    "    X = X.astype('float32')\n",
    "    X = X / 255.0\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71aa8bda",
   "metadata": {},
   "source": [
    "## Produce discriminator architecture\n",
    "\n",
    "Use Leaky ReLU activation function after convolutions to reduce vanishing gradient problem to ensure better training for kernels. Additionally use Leaky ReLU  to add non-linearity to improve variance in learned kernels and allow model to adapt to various features.\n",
    "\n",
    "Apply dropout layers as well to possibly remove some outputs and reduce overfitting.\n",
    "\n",
    "Discriminator compresses images down into feature space. It is trained on real and fake images; therefore model is a convolutional neural network for binary-classification. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8465630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 16, 16, 64)        640       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 8, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 4097      \n",
      "=================================================================\n",
      "Total params: 41,665\n",
      "Trainable params: 41,665\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.utils.vis_utils import plot_model\n",
    "\n",
    "def discriminator(in_shape=(64, 64, 1)):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(64, (3, 3), strides=(4, 4), padding='same', input_shape=in_shape))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Conv2D(64, (3, 3), strides=(2, 2), padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    opt = Adam(lr=0.0002, beta_1=0.5)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = discriminator()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38151970",
   "metadata": {},
   "source": [
    "## Load in all pokemon image samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9738b3a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(819, 64, 64, 1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX = load_samples()\n",
    "trainX.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46840c7d",
   "metadata": {},
   "source": [
    "## Produce real-image dataset for training discriminator\n",
    "\n",
    "Select random images from existing dataset and assign real class label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42ef8adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import ones\n",
    "from numpy import zeros\n",
    "from numpy.random import rand\n",
    "from numpy.random import randint\n",
    "\n",
    "def generate_real_samples(dataset, n):\n",
    "    ind = randint(0, dataset.shape[0], n)\n",
    "    X = dataset[ind]\n",
    "    y = ones((n, 1))\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1f863e",
   "metadata": {},
   "source": [
    "## Produce fake-image dataset for training discriminator\n",
    "\n",
    "Create pixel-space for however many image samples are selected. Then transform the pixel space into n random images and provide a class label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a79469b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_fake_samples(n):\n",
    "    X = rand(64 * 64 * n)\n",
    "    X = X.reshape((n, 64, 64, 1))\n",
    "    y = zeros((n, 1))\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7c8746",
   "metadata": {},
   "source": [
    "## Train discriminator\n",
    "\n",
    "Adjust kernel weights per each batch then check prediction accuracy. Train and test splits handled in background by function, train_on_batch().\n",
    "\n",
    "Keras by default ignores first dimension of input, therefore even though fake and real samples have shape (n, 64, 64, 1), Keras will read it in as (64, 64, 1) and work correctly.\n",
    "\n",
    "Additionally train_on_batch() is a specialised training algorithm as opposed to fit(). Training in batches reduces memory overhead and reduces processing time. \n",
    "\n",
    "Notice fast convergence of algorithm. Due to strongly randomized fake images it works quickly, however later when discriminator competes with generator, training time will increase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b076ec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">1 real=61% fake=16%\n",
      ">2 real=77% fake=11%\n",
      ">3 real=88% fake=8%\n",
      ">4 real=89% fake=6%\n",
      ">5 real=88% fake=5%\n",
      ">6 real=97% fake=3%\n",
      ">7 real=95% fake=3%\n",
      ">8 real=100% fake=5%\n",
      ">9 real=98% fake=3%\n",
      ">10 real=100% fake=0%\n",
      ">11 real=100% fake=2%\n",
      ">12 real=100% fake=3%\n",
      ">13 real=100% fake=3%\n",
      ">14 real=100% fake=2%\n",
      ">15 real=97% fake=6%\n",
      ">16 real=100% fake=0%\n",
      ">17 real=100% fake=2%\n",
      ">18 real=100% fake=3%\n",
      ">19 real=100% fake=2%\n",
      ">20 real=100% fake=5%\n",
      ">21 real=100% fake=2%\n",
      ">22 real=100% fake=0%\n",
      ">23 real=100% fake=0%\n",
      ">24 real=100% fake=3%\n",
      ">25 real=100% fake=2%\n",
      ">26 real=100% fake=5%\n",
      ">27 real=100% fake=0%\n",
      ">28 real=100% fake=3%\n",
      ">29 real=100% fake=2%\n",
      ">30 real=100% fake=2%\n",
      ">31 real=100% fake=0%\n",
      ">32 real=100% fake=2%\n",
      ">33 real=100% fake=5%\n",
      ">34 real=100% fake=5%\n",
      ">35 real=100% fake=5%\n",
      ">36 real=100% fake=2%\n",
      ">37 real=100% fake=6%\n",
      ">38 real=100% fake=23%\n",
      ">39 real=100% fake=22%\n",
      ">40 real=100% fake=42%\n",
      ">41 real=100% fake=25%\n",
      ">42 real=100% fake=34%\n",
      ">43 real=100% fake=64%\n",
      ">44 real=100% fake=58%\n",
      ">45 real=100% fake=64%\n",
      ">46 real=100% fake=73%\n",
      ">47 real=100% fake=78%\n",
      ">48 real=100% fake=86%\n",
      ">49 real=100% fake=86%\n",
      ">50 real=100% fake=88%\n"
     ]
    }
   ],
   "source": [
    "def train_discriminator(model, dataset, n_iter=50, n_batch=128):\n",
    "    half_batch = int(n_batch/2)\n",
    "    \n",
    "    for i in range(n_iter):\n",
    "        X_real, y_real = generate_real_samples(dataset, half_batch)\n",
    "        _, real_acc = model.train_on_batch(X_real, y_real)\n",
    "        X_fake, y_fake = generate_fake_samples(half_batch)\n",
    "        _, fake_acc = model.train_on_batch(X_fake, y_fake)\n",
    "        print('>%d real=%.0f%% fake=%.0f%%' % (i+1, real_acc*100, fake_acc*100))\n",
    "\n",
    "model = discriminator()\n",
    "train_discriminator(model, trainX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885f1ef8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
